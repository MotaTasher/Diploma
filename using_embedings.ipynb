{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from Code import Dataloader\n",
    "from Code import Dataset\n",
    "from Code import ModelBertV1\n",
    "from Code import Train\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Code.ModelBertV1 as ModelLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model(path, map_location='cuda'):\n",
    "    checkpoint = torch.load(path, map_location=map_location, weights_only=False)\n",
    "    config = checkpoint.get('config', None)\n",
    "    config['df_config']['address_limit'] = config['cnt_known_address']\n",
    "    model = getattr(ModelBertV1, config['model'])(\n",
    "                known_address_len=config['cnt_known_address'],\n",
    "                **config['model_params']\n",
    "            )\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    epoch = checkpoint.get('epoch', None)\n",
    "\n",
    "    return model, config, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BertForTransactionRegressionV1' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/serialization.py:851\u001b[0m, in \u001b[0;36m_check_seekable\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 851\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m(f\u001b[38;5;241m.\u001b[39mtell())\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/nn/modules/module.py:1928\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1927\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1928\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1930\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BertForTransactionRegressionV1' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, config, epoch \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/motatasher/Documents/University/Diploma/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDiploma/models/model training on eth dataset v1, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtensor predict_qjmctedofg/model_epoch_151.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(path, map_location)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_model\u001b[39m(path, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     config \u001b[38;5;241m=\u001b[39m checkpoint\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m     config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_config\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maddress_limit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnt_known_address\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/serialization.py:1425\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1423\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1425\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1427\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1428\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/serialization.py:756\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _open_buffer_writer(name_or_buffer)\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m--> 756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_buffer_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in mode but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/serialization.py:741\u001b[0m, in \u001b[0;36m_open_buffer_reader.__init__\u001b[0;34m(self, buffer)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, buffer):\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(buffer)\n\u001b[0;32m--> 741\u001b[0m     \u001b[43m_check_seekable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/serialization.py:854\u001b[0m, in \u001b[0;36m_check_seekable\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (io\u001b[38;5;241m.\u001b[39mUnsupportedOperation, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 854\u001b[0m     \u001b[43mraise_err_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseek\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/serialization.py:847\u001b[0m, in \u001b[0;36m_check_seekable.<locals>.raise_err_msg\u001b[0;34m(patterns, e)\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n\u001b[1;32m    841\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    842\u001b[0m             \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m    843\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. You can only torch.load from a file that is seekable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please pre-load the data into a buffer like io.BytesIO and\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    845\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m try to load from it instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    846\u001b[0m         )\n\u001b[0;32m--> 847\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(msg)\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BertForTransactionRegressionV1' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead."
     ]
    }
   ],
   "source": [
    "model, config, epoch = load_model(model,\n",
    "                                  '/home/motatasher/Documents/University/Diploma/' \\\n",
    "                                  'Diploma/models/model training on eth dataset v1, ' \\\n",
    "                                  'tensor predict_qjmctedofg/model_epoch_151.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "square std of all: 9339.15481948\n",
      "Train: 7457.2568177150715\n",
      "Val: 14984.751691976424\n"
     ]
    }
   ],
   "source": [
    "df_raw = getattr(Dataloader, config['dataset_fabric'])(**config['df_config'])\n",
    "print(config['cnt_known_address'])\n",
    "known_address = pd.concat([df_raw['to'], df_raw['from']])\\\n",
    "                    .value_counts()[:config['cnt_known_address']]\\\n",
    "                    .keys().sort_values()\n",
    "\n",
    "dataset_params = {\n",
    "    'known_address': list(known_address),\n",
    "    'sample_len': config['sample_len']\n",
    "}\n",
    "\n",
    "train_data, val_data = train_test_split(df_raw, test_size=1/4, shuffle=False)\n",
    "print(f\"square std of all: {df_raw['value'].std() ** 2}\\nTrain: {train_data['value'].std() ** 2}\\nVal: {val_data['value'].std() ** 2}\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    Dataset.TransactionDataset(train_data, **dataset_params, apply_log=config['use_log']),\n",
    "    batch_size=config['train_batch_size'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    Dataset.TransactionDataset(val_data, **dataset_params, apply_log=config['use_log']),\n",
    "    batch_size=config['test_batch_size'],\n",
    "    shuffle=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_ts(data):\n",
    "    return (data.loc[:, 'timestamp'].values.astype('datetime64[ns]') -  np.datetime64('1970-01-01T00:00:00')) \\\n",
    "            / np.timedelta64(1, 'ns')\n",
    "\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TimeEmbeddingRegressionDataset(data.Dataset):\n",
    "    def __init__(self, df, model, sample_len, apply_log=False,\n",
    "                 device='cuda', batch_size=128, cnt_batchs=8):\n",
    "        self.model = model.eval().to(device)\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.sample_len = sample_len\n",
    "        self.apply_log = apply_log\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.cnt_batchs = cnt_batchs\n",
    "\n",
    "        self.samples = self.build_samples(df)\n",
    "        self.embeddings, self.targets = self.compute_all_embeddings()\n",
    "\n",
    "    def build_samples(self, df):\n",
    "        return list(range(\n",
    "            min(len(df), self.batch_size * self.sample_len * self.cnt_batchs) // self.sample_len * self.sample_len))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def compute_all_embeddings(self):\n",
    "        all_embs, all_tgts = [], []\n",
    "        loader = DataLoader(self.samples[::self.sample_len], batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        for batch_indices in tqdm(itertools.islice(loader, self.cnt_batchs), desc=\"Embedding calculation\", total=\n",
    "                                  min(self.cnt_batchs, len(loader))):\n",
    "            batch = [self._prepare_sample(int(idx)) for idx in batch_indices]\n",
    "\n",
    "            model_inputs = self._collate_inputs([b[0] for b in batch])\n",
    "            targets = torch.stack([b[1] for b in batch]).to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                result = self.model(**model_inputs)['result']\n",
    "\n",
    "            all_embs.append(result.cpu())\n",
    "            all_tgts.append(targets.cpu())\n",
    "\n",
    "        print(torch.cat(all_embs, 0).shape)\n",
    "        return torch.cat(all_embs, 0).reshape(-1, all_embs[0].shape[-1]), torch.cat(all_tgts, 0).reshape(-1, 1)\n",
    "\n",
    "    def _prepare_sample(self, idx):\n",
    "        i = idx\n",
    "        batch_df = self.df.iloc[i:i + self.sample_len]\n",
    "        ts = get_ts(batch_df)\n",
    "        time_features = Dataset.extract_time_features(ts)\n",
    "        from_ind = batch_df['from'].values\n",
    "        to_ind = batch_df['to'].values\n",
    "        values = batch_df['value'].values\n",
    "\n",
    "        volume_converter = lambda x: x\n",
    "        if self.apply_log:\n",
    "            volume_converter = lambda x: np.log(x)\n",
    "\n",
    "        sample = {\n",
    "            'numeric_features': torch.tensor(values, dtype=torch.float).T.unsqueeze(0).unsqueeze(-1),\n",
    "            'from_address': torch.tensor(from_ind, dtype=torch.long).T.unsqueeze(0),\n",
    "            'to_address': torch.tensor(to_ind, dtype=torch.long).T.unsqueeze(0),\n",
    "            'time_features': torch.tensor(time_features, dtype=torch.float).T.unsqueeze(0),\n",
    "            'value': torch.tensor(volume_converter(values)).unsqueeze(0).unsqueeze(-1)\n",
    "        }\n",
    "\n",
    "        msk_ind, change_ind, save_ind, model_input = Train.batch_to_model(\n",
    "            sample,\n",
    "            p_msk=0.0,\n",
    "            p_change=0.0,\n",
    "            p_save=1.0,\n",
    "            device=self.device,\n",
    "            change_strategy=Train.uniform_change_strategy\n",
    "        )\n",
    "\n",
    "        target = torch.tensor(ts, dtype=torch.float)\n",
    "        return model_input, target\n",
    "\n",
    "    def _collate_inputs(self, input_list):\n",
    "        batched = {}\n",
    "        for key in input_list[0].keys():\n",
    "            batched[key] = torch.cat([torch.tensor(item[key]) for item in input_list], dim=0)\n",
    "        return batched\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.targets[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding calculation:   0%|          | 0/95 [00:00<?, ?it/s]/tmp/ipykernel_3079870/1555572793.py:72: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3725.)\n",
      "  'numeric_features': torch.tensor(values, dtype=torch.float).T.unsqueeze(0).unsqueeze(-1),\n",
      "/tmp/ipykernel_3079870/1555572793.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batched[key] = torch.cat([torch.tensor(item[key]) for item in input_list], dim=0)\n",
      "Embedding calculation: 100%|██████████| 95/95 [00:32<00:00,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12148, 100, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eazy_df = TimeEmbeddingRegressionDataset(df_raw, model, 100, apply_log=True, cnt_batchs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "class SimpleRegressor(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyLinear(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def train_time_regressor(model, train_dataloader, val_dataloader, num_epochs=100, lr=10, device='cuda', std=1, mean=0, normilize=True):\n",
    "    std = float(std)\n",
    "    mean = float(mean)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        verbose=True,\n",
    "        min_lr=1e-8,\n",
    "        threshold=1,\n",
    "    )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        for emb_time, target in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1} - Train\"):\n",
    "            if normilize:\n",
    "                emb_time = emb_time / emb_time.norm(2, 1, keepdim=True)\n",
    "            emb_time = emb_time.to(device)\n",
    "            target = (target.to(device).unsqueeze(-1).float() - mean) / std\n",
    "\n",
    "            pred = model(emb_time)\n",
    "            loss = criterion(pred, target)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for emb_time, target in tqdm(val_dataloader, desc=f\"Epoch {epoch + 1} - Val\"):\n",
    "                if normilize:\n",
    "                    emb_time = emb_time / emb_time.norm(2, 1, keepdim=True)\n",
    "                emb_time = emb_time.to(device)\n",
    "                target = (target.to(device).unsqueeze(-1).float() - mean) / std\n",
    "\n",
    "                pred = model(emb_time)\n",
    "                loss = criterion(pred, target)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = (total_val_loss / len(val_dataloader)) ** 0.5 * std\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}\")\n",
    "        print(f\"\\nLr: {optimizer.param_groups[0]['lr']}\")\n",
    "        print(f\"\\nTrain Loss: {(total_train_loss / len(train_dataloader)) ** 0.5 * std:.4f}\")\n",
    "        print(f\"\\nVal Loss: {avg_val_loss:.4f}\")\n",
    "        print(f\"\\nTimedelta: {datetime.timedelta(seconds=avg_val_loss)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_model = SimpleRegressor(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader =  DataLoader(eazy_df, 2 ** 14, drop_last=True, num_workers=12, persistent_workers=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch 1:   0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([16384, 1, 1])) that is different to the input size (torch.Size([16384, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch 1: 100%|██████████| 74/74 [00:02<00:00, 28.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Lr: 1\n",
      "Loss: 2271391.5484\n",
      "timedelta 26 days, 6:56:31.548361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 74/74 [00:01<00:00, 46.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "Lr: 1\n",
      "Loss: 263269.0129\n",
      "timedelta 3 days, 1:07:49.012857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 74/74 [00:01<00:00, 39.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      "Lr: 1\n",
      "Loss: 263117.1862\n",
      "timedelta 3 days, 1:05:17.186236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 74/74 [00:01<00:00, 41.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      "Lr: 1\n",
      "Loss: 263178.3276\n",
      "timedelta 3 days, 1:06:18.327610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 74/74 [00:02<00:00, 36.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n",
      "Lr: 1\n",
      "Loss: 263219.4992\n",
      "timedelta 3 days, 1:06:59.499175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 74/74 [00:01<00:00, 38.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n",
      "Lr: 0.5\n",
      "Loss: 263239.8841\n",
      "timedelta 3 days, 1:07:19.884091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 74/74 [00:01<00:00, 38.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n",
      "Lr: 0.5\n",
      "Loss: 263131.8098\n",
      "timedelta 3 days, 1:05:31.809831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 74/74 [00:02<00:00, 34.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n",
      "Lr: 0.5\n",
      "Loss: 263109.7832\n",
      "timedelta 3 days, 1:05:09.783230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 74/74 [00:02<00:00, 29.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n",
      "Lr: 0.5\n",
      "Loss: 263134.6167\n",
      "timedelta 3 days, 1:05:34.616711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 74/74 [00:02<00:00, 34.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n",
      "Lr: 0.5\n",
      "Loss: 263157.6705\n",
      "timedelta 3 days, 1:05:57.670452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 74/74 [00:02<00:00, 31.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11\n",
      "Lr: 0.5\n",
      "Loss: 263179.2268\n",
      "timedelta 3 days, 1:06:19.226779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 74/74 [00:01<00:00, 43.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12\n",
      "Lr: 0.25\n",
      "Loss: 263198.4099\n",
      "timedelta 3 days, 1:06:38.409943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 74/74 [00:01<00:00, 41.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13\n",
      "Lr: 0.25\n",
      "Loss: 263075.3073\n",
      "timedelta 3 days, 1:04:35.307250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 74/74 [00:02<00:00, 29.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14\n",
      "Lr: 0.25\n",
      "Loss: 263046.4684\n",
      "timedelta 3 days, 1:04:06.468389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 74/74 [00:01<00:00, 54.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15\n",
      "Lr: 0.25\n",
      "Loss: 263058.1362\n",
      "timedelta 3 days, 1:04:18.136182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 74/74 [00:01<00:00, 41.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16\n",
      "Lr: 0.25\n",
      "Loss: 263070.2000\n",
      "timedelta 3 days, 1:04:30.199981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 74/74 [00:02<00:00, 36.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17\n",
      "Lr: 0.25\n",
      "Loss: 263082.7562\n",
      "timedelta 3 days, 1:04:42.756154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 74/74 [00:01<00:00, 49.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18\n",
      "Lr: 0.125\n",
      "Loss: 263095.7871\n",
      "timedelta 3 days, 1:04:55.787149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 74/74 [00:01<00:00, 43.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19\n",
      "Lr: 0.125\n",
      "Loss: 263000.4123\n",
      "timedelta 3 days, 1:03:20.412313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 74/74 [00:01<00:00, 42.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20\n",
      "Lr: 0.125\n",
      "Loss: 262990.9677\n",
      "timedelta 3 days, 1:03:10.967699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 74/74 [00:01<00:00, 41.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21\n",
      "Lr: 0.125\n",
      "Loss: 262996.2312\n",
      "timedelta 3 days, 1:03:16.231154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 74/74 [00:02<00:00, 36.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22\n",
      "Lr: 0.125\n",
      "Loss: 263001.9413\n",
      "timedelta 3 days, 1:03:21.941265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 74/74 [00:01<00:00, 51.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23\n",
      "Lr: 0.125\n",
      "Loss: 263007.9464\n",
      "timedelta 3 days, 1:03:27.946434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 74/74 [00:01<00:00, 40.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24\n",
      "Lr: 0.0625\n",
      "Loss: 263014.2584\n",
      "timedelta 3 days, 1:03:34.258408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 74/74 [00:02<00:00, 33.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25\n",
      "Lr: 0.0625\n",
      "Loss: 262956.6192\n",
      "timedelta 3 days, 1:02:36.619151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 74/74 [00:01<00:00, 45.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26\n",
      "Lr: 0.0625\n",
      "Loss: 262955.5952\n",
      "timedelta 3 days, 1:02:35.595187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 74/74 [00:01<00:00, 43.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27\n",
      "Lr: 0.0625\n",
      "Loss: 262958.3900\n",
      "timedelta 3 days, 1:02:38.389955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 74/74 [00:02<00:00, 35.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28\n",
      "Lr: 0.0625\n",
      "Loss: 262961.2559\n",
      "timedelta 3 days, 1:02:41.255932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 74/74 [00:01<00:00, 53.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29\n",
      "Lr: 0.0625\n",
      "Loss: 262964.2503\n",
      "timedelta 3 days, 1:02:44.250253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 74/74 [00:01<00:00, 49.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30\n",
      "Lr: 0.03125\n",
      "Loss: 262967.3825\n",
      "timedelta 3 days, 1:02:47.382454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 74/74 [00:01<00:00, 37.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31\n",
      "Lr: 0.03125\n",
      "Loss: 262934.1504\n",
      "timedelta 3 days, 1:02:14.150401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 74/74 [00:01<00:00, 40.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32\n",
      "Lr: 0.03125\n",
      "Loss: 262934.6264\n",
      "timedelta 3 days, 1:02:14.626431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 74/74 [00:01<00:00, 42.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33\n",
      "Lr: 0.03125\n",
      "Loss: 262936.1029\n",
      "timedelta 3 days, 1:02:16.102862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 74/74 [00:02<00:00, 36.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34\n",
      "Lr: 0.03125\n",
      "Loss: 262937.6381\n",
      "timedelta 3 days, 1:02:17.638125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 74/74 [00:01<00:00, 39.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35\n",
      "Lr: 0.03125\n",
      "Loss: 262939.2327\n",
      "timedelta 3 days, 1:02:19.232748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 74/74 [00:02<00:00, 31.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36\n",
      "Lr: 0.015625\n",
      "Loss: 262940.9005\n",
      "timedelta 3 days, 1:02:20.900515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 74/74 [00:02<00:00, 34.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37\n",
      "Lr: 0.015625\n",
      "Loss: 262921.5808\n",
      "timedelta 3 days, 1:02:01.580769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 74/74 [00:01<00:00, 54.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38\n",
      "Lr: 0.015625\n",
      "Loss: 262922.0669\n",
      "timedelta 3 days, 1:02:02.066895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 74/74 [00:02<00:00, 35.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39\n",
      "Lr: 0.015625\n",
      "Loss: 262922.8620\n",
      "timedelta 3 days, 1:02:02.861975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 74/74 [00:01<00:00, 42.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40\n",
      "Lr: 0.015625\n",
      "Loss: 262923.7183\n",
      "timedelta 3 days, 1:02:03.718336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 74/74 [00:01<00:00, 39.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41\n",
      "Lr: 0.015625\n",
      "Loss: 262924.6121\n",
      "timedelta 3 days, 1:02:04.612120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 74/74 [00:02<00:00, 35.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42\n",
      "Lr: 0.0078125\n",
      "Loss: 262925.5385\n",
      "timedelta 3 days, 1:02:05.538451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 74/74 [00:01<00:00, 43.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43\n",
      "Lr: 0.0078125\n",
      "Loss: 262914.0817\n",
      "timedelta 3 days, 1:01:54.081707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 74/74 [00:01<00:00, 43.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44\n",
      "Lr: 0.0078125\n",
      "Loss: 262914.4344\n",
      "timedelta 3 days, 1:01:54.434357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 74/74 [00:01<00:00, 44.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45\n",
      "Lr: 0.0078125\n",
      "Loss: 262914.8820\n",
      "timedelta 3 days, 1:01:54.882007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 74/74 [00:02<00:00, 36.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46\n",
      "Lr: 0.0078125\n",
      "Loss: 262915.3722\n",
      "timedelta 3 days, 1:01:55.372174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 74/74 [00:02<00:00, 32.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47\n",
      "Lr: 0.0078125\n",
      "Loss: 262915.8823\n",
      "timedelta 3 days, 1:01:55.882273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 74/74 [00:01<00:00, 37.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48\n",
      "Lr: 0.00390625\n",
      "Loss: 262916.4165\n",
      "timedelta 3 days, 1:01:56.416546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 74/74 [00:01<00:00, 42.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49\n",
      "Lr: 0.00390625\n",
      "Loss: 262909.5152\n",
      "timedelta 3 days, 1:01:49.515240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 74/74 [00:01<00:00, 42.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "Lr: 0.00390625\n",
      "Loss: 262909.7500\n",
      "timedelta 3 days, 1:01:49.749991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 74/74 [00:01<00:00, 42.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51\n",
      "Lr: 0.00390625\n",
      "Loss: 262910.0136\n",
      "timedelta 3 days, 1:01:50.013582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 74/74 [00:01<00:00, 52.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52\n",
      "Lr: 0.00390625\n",
      "Loss: 262910.2968\n",
      "timedelta 3 days, 1:01:50.296787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 74/74 [00:01<00:00, 43.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53\n",
      "Lr: 0.00390625\n",
      "Loss: 262910.5923\n",
      "timedelta 3 days, 1:01:50.592292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 74/74 [00:01<00:00, 40.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54\n",
      "Lr: 0.001953125\n",
      "Loss: 262910.9007\n",
      "timedelta 3 days, 1:01:50.900733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 74/74 [00:01<00:00, 40.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55\n",
      "Lr: 0.001953125\n",
      "Loss: 262906.7120\n",
      "timedelta 3 days, 1:01:46.712001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 74/74 [00:02<00:00, 36.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56\n",
      "Lr: 0.001953125\n",
      "Loss: 262906.8620\n",
      "timedelta 3 days, 1:01:46.862035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 74/74 [00:01<00:00, 41.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57\n",
      "Lr: 0.001953125\n",
      "Loss: 262907.0183\n",
      "timedelta 3 days, 1:01:47.018325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 74/74 [00:01<00:00, 37.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58\n",
      "Lr: 0.001953125\n",
      "Loss: 262907.1816\n",
      "timedelta 3 days, 1:01:47.181613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 74/74 [00:01<00:00, 40.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59\n",
      "Lr: 0.001953125\n",
      "Loss: 262907.3547\n",
      "timedelta 3 days, 1:01:47.354655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 74/74 [00:01<00:00, 46.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60\n",
      "Lr: 0.0009765625\n",
      "Loss: 262907.5352\n",
      "timedelta 3 days, 1:01:47.535226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 74/74 [00:02<00:00, 36.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61\n",
      "Lr: 0.0009765625\n",
      "Loss: 262904.9845\n",
      "timedelta 3 days, 1:01:44.984534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 74/74 [00:02<00:00, 35.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62\n",
      "Lr: 0.0009765625\n",
      "Loss: 262905.0747\n",
      "timedelta 3 days, 1:01:45.074661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 74/74 [00:01<00:00, 47.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63\n",
      "Lr: 0.0009765625\n",
      "Loss: 262905.1685\n",
      "timedelta 3 days, 1:01:45.168499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 74/74 [00:01<00:00, 44.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64\n",
      "Lr: 0.0009765625\n",
      "Loss: 262905.2633\n",
      "timedelta 3 days, 1:01:45.263291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 74/74 [00:01<00:00, 43.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65\n",
      "Lr: 0.0009765625\n",
      "Loss: 262905.3617\n",
      "timedelta 3 days, 1:01:45.361689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|██████████| 74/74 [00:01<00:00, 45.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66\n",
      "Lr: 0.00048828125\n",
      "Loss: 262905.4651\n",
      "timedelta 3 days, 1:01:45.465070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████| 74/74 [00:01<00:00, 44.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67\n",
      "Lr: 0.00048828125\n",
      "Loss: 262903.9180\n",
      "timedelta 3 days, 1:01:43.917956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|██████████| 74/74 [00:02<00:00, 33.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68\n",
      "Lr: 0.00048828125\n",
      "Loss: 262903.9725\n",
      "timedelta 3 days, 1:01:43.972456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|██████████| 74/74 [00:01<00:00, 41.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69\n",
      "Lr: 0.00048828125\n",
      "Loss: 262904.0249\n",
      "timedelta 3 days, 1:01:44.024942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 100%|██████████| 74/74 [00:01<00:00, 37.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70\n",
      "Lr: 0.00048828125\n",
      "Loss: 262904.0785\n",
      "timedelta 3 days, 1:01:44.078489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71: 100%|██████████| 74/74 [00:01<00:00, 43.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71\n",
      "Lr: 0.00048828125\n",
      "Loss: 262904.1342\n",
      "timedelta 3 days, 1:01:44.134156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 100%|██████████| 74/74 [00:02<00:00, 35.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72\n",
      "Lr: 0.000244140625\n",
      "Loss: 262904.1891\n",
      "timedelta 3 days, 1:01:44.189081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 100%|██████████| 74/74 [00:02<00:00, 32.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73\n",
      "Lr: 0.000244140625\n",
      "Loss: 262903.2637\n",
      "timedelta 3 days, 1:01:43.263735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 100%|██████████| 74/74 [00:01<00:00, 45.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74\n",
      "Lr: 0.000244140625\n",
      "Loss: 262903.2928\n",
      "timedelta 3 days, 1:01:43.292788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 100%|██████████| 74/74 [00:01<00:00, 41.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75\n",
      "Lr: 0.000244140625\n",
      "Loss: 262903.3212\n",
      "timedelta 3 days, 1:01:43.321205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|██████████| 74/74 [00:01<00:00, 45.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76\n",
      "Lr: 0.000244140625\n",
      "Loss: 262903.3499\n",
      "timedelta 3 days, 1:01:43.349940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77: 100%|██████████| 74/74 [00:01<00:00, 43.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77\n",
      "Lr: 0.000244140625\n",
      "Loss: 262903.3799\n",
      "timedelta 3 days, 1:01:43.379947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78: 100%|██████████| 74/74 [00:01<00:00, 40.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78\n",
      "Lr: 0.0001220703125\n",
      "Loss: 262903.4084\n",
      "timedelta 3 days, 1:01:43.408364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79: 100%|██████████| 74/74 [00:01<00:00, 44.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79\n",
      "Lr: 0.0001220703125\n",
      "Loss: 262902.8621\n",
      "timedelta 3 days, 1:01:42.862083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80: 100%|██████████| 74/74 [00:01<00:00, 45.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80\n",
      "Lr: 0.0001220703125\n",
      "Loss: 262902.8764\n",
      "timedelta 3 days, 1:01:42.876398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 100%|██████████| 74/74 [00:01<00:00, 39.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81\n",
      "Lr: 0.0001220703125\n",
      "Loss: 262902.8884\n",
      "timedelta 3 days, 1:01:42.888379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82:  65%|██████▍   | 48/74 [00:01<00:00, 44.94it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_time_regressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meazy_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meazy_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[89], line 39\u001b[0m, in \u001b[0;36mtrain_time_regressor\u001b[0;34m(model, dataloader, num_epochs, lr, device, std, mean)\u001b[0m\n\u001b[1;32m     37\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     38\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 39\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43memb_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43memb_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43memb_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43memb_time\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43memb_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43memb_time\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1458\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1457\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1458\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1410\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1409\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1410\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1411\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1412\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1251\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1239\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1251\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1254\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1255\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1256\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_time_regressor(time_model, dataloader,\n",
    "                     lr=1, device=device, std=eazy_df[:][1].std(), mean=eazy_df[:][1].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "def plot_time_predictions(model, dataloader, device='cuda', mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for emb_time, target in tqdm(dataloader, desc=\"Predicting\"):\n",
    "            emb_time = emb_time / emb_time.norm(2, 1, keepdim=True)\n",
    "            emb_time = emb_time.to(device)\n",
    "            target = target.unsqueeze(-1).float().to(device)\n",
    "\n",
    "            preds = model(emb_time)\n",
    "            preds_real = preds * std + mean\n",
    "            targets_real = target\n",
    "\n",
    "            all_preds.append(preds_real.cpu())\n",
    "            all_targets.append(targets_real.cpu())\n",
    "\n",
    "    preds_tensor = torch.cat(all_preds).squeeze().numpy()\n",
    "    targets_tensor = torch.cat(all_targets).squeeze().numpy()\n",
    "\n",
    "    # Перевод в datetime (unix time → datetime)\n",
    "    # preds_datetime = [datetime.fromtimestamp(ts) for ts in preds_tensor]\n",
    "    # targets_datetime = [datetime.fromtimestamp(ts) for ts in targets_tensor]\n",
    "\n",
    "    return preds_tensor, targets_tensor\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 74/74 [00:01<00:00, 41.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# dataloader_final =  DataLoader(eazy_df, 2 ** 14, drop_last=True, num_workers=12, shuffle=False)\n",
    "data_mean, data_std = eazy_df[:][1].mean().numpy().item(), eazy_df[:][1].std().numpy().item()\n",
    "\n",
    "preds_tensor, targets_tensor = plot_time_predictions(time_model, dataloader, device, data_mean, data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0013],\n",
       "        [0.0013],\n",
       "        [0.0013],\n",
       "        ...,\n",
       "        [0.0013],\n",
       "        [0.0013],\n",
       "        [0.0013]], device='cuda:1', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_model(eazy_df[:][0].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_datetime = [datetime.datetime.fromtimestamp(float(ts)) for ts in preds_tensor]\n",
    "targets_datetime = [datetime.datetime.fromtimestamp(float(ts)) for ts in targets_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3079870/1478482353.py:13: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
      "  plt.ylim(min(preds_datetime), max(preds_datetime))\n",
      "/tmp/ipykernel_3079870/1478482353.py:15: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Построение\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(targets_datetime, preds_datetime, alpha=0.3, s=8)\n",
    "# plt.plot(\n",
    "#     [min(targets_datetime), max(targets_datetime)],\n",
    "#     [min(targets_datetime), max(targets_datetime)],\n",
    "#     color='red', linestyle='--', label='y = x (ideal)'\n",
    "# )\n",
    "plt.xlabel(\"True Time\")\n",
    "plt.ylabel(\"Predicted Time\")\n",
    "plt.title(\"Predicted vs True Time\")\n",
    "\n",
    "plt.ylim(min(preds_datetime), max(preds_datetime))\n",
    "plt.xticks(rotation=30)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# plot_predictions(time_model, DataLoader(eazy_df, 2 ** 14, drop_last=True, num_workers=12), device, coef=eazy_df[:][1].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(eazy_df[0][0], dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (eazy_df[0][0] ** 2).sum(0) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  torch.norm(eazy_df[0][0], 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (eazy_df[0][0] / torch.norm(eazy_df[0][0], 2, 0)).diff(1).norm(2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/1214800 [00:00<?, ?it/s]/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch 1:   0%|          | 1643/1214800 [00:03<41:00, 493.13it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[244], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_time_regressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSimpleRegressor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meazy_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[233], line 41\u001b[0m, in \u001b[0;36mtrain_time_regressor\u001b[0;34m(model, dataloader, num_epochs, lr, device)\u001b[0m\n\u001b[1;32m     38\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[0;32m---> 41\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# optimizer.zero_grad()\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# optimizer.step()\u001b[39;00m\n\u001b[1;32m     47\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/optim/lbfgs.py:451\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    448\u001b[0m     opt_cond \u001b[38;5;241m=\u001b[39m flat_grad\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tolerance_grad\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;66;03m# no line search, simply move with fixed-step\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_iter \u001b[38;5;241m!=\u001b[39m max_iter:\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;66;03m# re-evaluate function only if not in last iteration\u001b[39;00m\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;66;03m# the reason we do this: in a stochastic setting,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;66;03m# no use to re-evaluate that function here\u001b[39;00m\n\u001b[1;32m    456\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/optim/lbfgs.py:283\u001b[0m, in \u001b[0;36mLBFGS._add_grad\u001b[0;34m(self, step_size, update)\u001b[0m\n\u001b[1;32m    281\u001b[0m     numel \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# view as to avoid deprecated pointwise semantics\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     p\u001b[38;5;241m.\u001b[39madd_(\u001b[43mupdate\u001b[49m\u001b[43m[\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m, alpha\u001b[38;5;241m=\u001b[39mstep_size)\n\u001b[1;32m    284\u001b[0m     offset \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m numel\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m offset \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numel()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_time_regressor(SimpleRegressor(32), eazy_df, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43meazy_df\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[73], line 28\u001b[0m, in \u001b[0;36mTimeEmbeddingRegressionDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     26\u001b[0m from_ind \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m to_ind \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 28\u001b[0m numeric_features \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m volume_converter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: x\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_log\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "\u001b[0;31mValueError\u001b[0m: could not determine the shape of object type 'Series'"
     ]
    }
   ],
   "source": [
    "for a, b in eazy_df:\n",
    "    print(b.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DiplomaIsupov",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
