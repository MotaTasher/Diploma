{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from Code import Dataloader\n",
    "from Code import Dataset\n",
    "from Code import ModelBertV1\n",
    "from Code import Train\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Code.Dataloader as loader\n",
    "# fetcher = loader.SyncBatchEthFetcher(batch_size=500)\n",
    "# last_ind = int(2e7 + 1e6)\n",
    "# size = 100_000\n",
    "\n",
    "# df_txs = fetcher.get_transactions(last_ind - size, last_ind, use_async=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Code.ModelBertV1 as ModelLib\n",
    "model = ModelLib.BertForTransactionRegressionV1(100, 32, False, 12, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def load_model(model, path, map_location='cuda'):\n",
    "    checkpoint = torch.load(path, map_location=map_location, weights_only=False)\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    config = checkpoint.get('config', None)\n",
    "    epoch = checkpoint.get('epoch', None)\n",
    "\n",
    "    return model, config, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, config, epoch = load_model(model,\n",
    "                                  '/home/motatasher/Documents/University/Diploma/' \\\n",
    "                                  'Diploma/models/model training on eth dataset v1, ' \\\n",
    "                                  'tensor predict_qjmctedofg/model_epoch_151.pt')\n",
    "config['df_config']['address_limit'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'model training on eth dataset v1, tensor predict',\n",
       " 'df_config': {'cnt': 50000, 'start_block': 20900000, 'end_block': 21000000, 'address_limit': 100, 'use_async': False},\n",
       " 'dataset_fabric': 'GetEthereumDataset',\n",
       " 'train_batch_size': 512,\n",
       " 'test_batch_size': 64,\n",
       " 'sample_len': 100,\n",
       " 'cnt_known_address': 100,\n",
       " 'model': 'BertForTransactionRegressionV1',\n",
       " 'model_params': {'emb_size': 32, 'num_attention_heads': 12, 'use_compositor': False, 'time_features': 15},\n",
       " 'num_epochs': 1000,\n",
       " 'learning_rate': 3e-05,\n",
       " 'gamma': 0.3,\n",
       " 'step_size': 10,\n",
       " 'warmup_epochs': 10,\n",
       " 'time_coef_loss': 1,\n",
       " 'cnt_last_for_show': 50,\n",
       " 'seconds_betwen_image_show': 10,\n",
       " 'model_predictor': 'time_cross_predictior',\n",
       " 'result_loss': <function Code.Train.result_loss_slower_change(result, coef, **kwargs) -> torch.Tensor>,\n",
       " 'show_img': False,\n",
       " 'show_batch_size': 100,\n",
       " 'p_change': 0.15,\n",
       " 'p_msk': 0.15,\n",
       " 'p_save': 0.15,\n",
       " 'loggin_each': 5,\n",
       " 'change_strategy': <function Code.Train.uniform_change_strategy(shape) -> torch.Tensor>,\n",
       " 'loss_fn': <function Code.Train.criterion_loss_fn(pred, target, msk_ind, save_ind, change_ind, criterion) -> torch.Tensor>,\n",
       " 'start_epoch': 0,\n",
       " 'use_log': True,\n",
       " 'use_exp': False,\n",
       " 'save_each': 50,\n",
       " 'save_path': 'models',\n",
       " 'cuda_id': 5,\n",
       " 'run_id': 'qjmctedofg',\n",
       " 'predictor': <function Code.Train.time_cross_predictor(cls_result, result, from_emb, to_emb, use_compositor=False, model=None, exp_predict=False, **kwargs) -> torch.Tensor>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cnt': 50000, 'start_block': 20900000, 'end_block': 21000000, 'address_limit': 100, 'use_async': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['df_config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_block = 21100000\n",
    "end_block = 21200000\n",
    "\n",
    "address_limit = 100\n",
    "use_async = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e878c205a4e4df793815147006f7f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write at logger: logs/logs_470.log\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mDataloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetEthereumDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_block\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_block\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_block\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_block\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43maddress_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maddress_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_async\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_async\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/University/Diploma/Diploma/Code/Dataloader.py:441\u001b[0m, in \u001b[0;36mGetEthereumDataset\u001b[0;34m(start_block, end_block, address_limit, logger_fake, logger_name, cache_dir, batch_size, cnt, use_async)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mGetEthereumDataset\u001b[39m(\n\u001b[1;32m    422\u001b[0m     start_block: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m    423\u001b[0m     end_block: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    430\u001b[0m     use_async\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    431\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m    433\u001b[0m     fetcher \u001b[38;5;241m=\u001b[39m SyncBatchEthFetcher(\n\u001b[1;32m    434\u001b[0m         rpc_url\u001b[38;5;241m=\u001b[39mETH_RPC_URL,\n\u001b[1;32m    435\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    438\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    439\u001b[0m     )\n\u001b[0;32m--> 441\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mfetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_transactions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_block\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_block\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_async\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_async\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    443\u001b[0m     df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/University/Diploma/Diploma/Code/Dataloader.py:414\u001b[0m, in \u001b[0;36mSyncBatchEthFetcher.get_transactions\u001b[0;34m(self, start_block, end_block, use_async)\u001b[0m\n\u001b[1;32m    412\u001b[0m     blocks_json \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetch_blocks_async(block_list))\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 414\u001b[0m     blocks_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks_json_to_df(blocks_json)\n\u001b[1;32m    417\u001b[0m df\u001b[38;5;241m.\u001b[39mtimestamp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df\u001b[38;5;241m.\u001b[39mtimestamp \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1e9\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/University/Diploma/Diploma/Code/Dataloader.py:297\u001b[0m, in \u001b[0;36mSyncBatchEthFetcher.fetch_blocks\u001b[0;34m(self, block_nums)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# Save to cache\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(cache_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 297\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m logger\u001b[38;5;241m.\u001b[39mWrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetched and cached batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_start\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_end\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    300\u001b[0m all_results\u001b[38;5;241m.\u001b[39mextend(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/json/encoder.py:430\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m _floatstr(o)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 430\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/json/encoder.py:326\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 326\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/json/encoder.py:326\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 326\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/json/encoder.py:386\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m _key_separator\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnull\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Dataloader.GetEthereumDataset(\n",
    "    start_block=start_block,\n",
    "    end_block=end_block,\n",
    "    address_limit=address_limit,\n",
    "    use_async=use_async,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = getattr(Dataloader, config['dataset_fabric'])(**config['df_config'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb09f93d29c4fb69f4f9315368d89c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write at logger: logs/logs_448.log\n",
      "100\n",
      "square std of all: 9339.154819480005\n",
      "Train: 7457.256819637733\n",
      "Val: 14984.751685044885\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_raw = getattr(Dataloader, config['dataset_fabric'])(**config['df_config'])\n",
    "print(config['cnt_known_address'])\n",
    "known_address = pd.concat([df_raw['to'], df_raw['from']])\\\n",
    "                    .value_counts()[:config['cnt_known_address']]\\\n",
    "                    .keys().sort_values()\n",
    "\n",
    "dataset_params = {\n",
    "    'known_address': list(known_address),\n",
    "    'sample_len': config['sample_len']\n",
    "}\n",
    "\n",
    "train_data, val_data = train_test_split(df_raw, test_size=1/4, shuffle=False)\n",
    "print(f\"square std of all: {df_raw['value'].std() ** 2}\\nTrain: {train_data['value'].std() ** 2}\\nVal: {val_data['value'].std() ** 2}\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    Dataset.TransactionDataset(train_data, **dataset_params, apply_log=config['use_log']),\n",
    "    batch_size=config['train_batch_size'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    Dataset.TransactionDataset(val_data, **dataset_params, apply_log=config['use_log']),\n",
    "    batch_size=config['test_batch_size'],\n",
    "    shuffle=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.timestamp = pd.to_datetime(train_data.timestamp * 1e9)\n",
    "val_data.timestamp = pd.to_datetime(val_data.timestamp * 1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_raw.iloc[:1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(df_raw['timestamp']).astype('datetime64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1970-01-01 00:00:00')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_ts(data):\n",
    "    # return (pd.to_datetime(data['timestamp'] * 1e9) -  pd.to_datetime(0)).values \\\n",
    "    #         / np.timedelta64(1, 'ns')\n",
    "    return (data.loc[:, 'timestamp'].values.astype('datetime64[ns]') -  np.datetime64('1970-01-01T00:00:00')) \\\n",
    "            / np.timedelta64(1, 'ns')\n",
    "    # return data['timestamp'].values * 1e9\n",
    "\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TimeEmbeddingRegressionDataset(data.Dataset):\n",
    "    def __init__(self, df, model, sample_len, apply_log=False,\n",
    "                 device='cuda', batch_size=128, cnt_batchs=8):\n",
    "        self.model = model.eval().to(device)\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.sample_len = sample_len\n",
    "        self.apply_log = apply_log\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.cnt_batchs = cnt_batchs\n",
    "\n",
    "        self.samples = self.build_samples(df)\n",
    "        self.embeddings, self.targets = self.compute_all_embeddings()\n",
    "\n",
    "    def build_samples(self, df):\n",
    "        return list(range(\n",
    "            min(len(df), self.batch_size * self.sample_len * self.cnt_batchs) // self.sample_len * self.sample_len))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def compute_all_embeddings(self):\n",
    "        all_embs, all_tgts = [], []\n",
    "        loader = DataLoader(self.samples[::self.sample_len], batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        for batch_indices in tqdm(itertools.islice(loader, self.cnt_batchs), desc=\"Embedding calculation\", total=\n",
    "                                  min(self.cnt_batchs, len(loader))):\n",
    "            batch = [self._prepare_sample(int(idx)) for idx in batch_indices]\n",
    "            # print(batch_indices)\n",
    "            # print(batch[0])\n",
    "\n",
    "            model_inputs = self._collate_inputs([b[0] for b in batch])\n",
    "            targets = torch.stack([b[1] for b in batch]).to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                result = self.model(**model_inputs)['result']\n",
    "\n",
    "            all_embs.append(result.cpu())\n",
    "            all_tgts.append(targets.cpu())\n",
    "\n",
    "        print(torch.cat(all_embs, 0).shape)\n",
    "        return torch.cat(all_embs, 0).reshape(-1, all_embs[0].shape[-1]), torch.cat(all_tgts, 0).reshape(-1, 1)\n",
    "\n",
    "    def _prepare_sample(self, idx):\n",
    "        i = idx\n",
    "        batch_df = self.df.iloc[i:i + self.sample_len]\n",
    "        ts = get_ts(batch_df)\n",
    "        time_features = Dataset.extract_time_features(ts)\n",
    "        from_ind = batch_df['from'].values\n",
    "        to_ind = batch_df['to'].values\n",
    "        values = batch_df['value'].values\n",
    "\n",
    "        volume_converter = lambda x: x\n",
    "        if self.apply_log:\n",
    "            volume_converter = lambda x: np.log(x)\n",
    "\n",
    "        sample = {\n",
    "            'numeric_features': torch.tensor(values, dtype=torch.float).T.unsqueeze(0).unsqueeze(-1),\n",
    "            'from_address': torch.tensor(from_ind, dtype=torch.long).T.unsqueeze(0),\n",
    "            'to_address': torch.tensor(to_ind, dtype=torch.long).T.unsqueeze(0),\n",
    "            'time_features': torch.tensor(time_features, dtype=torch.float).T.unsqueeze(0),\n",
    "            'value': torch.tensor(volume_converter(values)).unsqueeze(0).unsqueeze(-1)\n",
    "        }\n",
    "\n",
    "        msk_ind, change_ind, save_ind, model_input = Train.batch_to_model(\n",
    "            sample,\n",
    "            p_msk=0.0,\n",
    "            p_change=0.0,\n",
    "            p_save=1.0,\n",
    "            device=self.device,\n",
    "            change_strategy=Train.uniform_change_strategy\n",
    "        )\n",
    "\n",
    "        target = torch.tensor(ts, dtype=torch.float)\n",
    "        return model_input, target\n",
    "\n",
    "    def _collate_inputs(self, input_list):\n",
    "        batched = {}\n",
    "        for key in input_list[0].keys():\n",
    "            batched[key] = torch.cat([torch.tensor(item[key]) for item in input_list], dim=0)\n",
    "        return batched\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.targets[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding calculation:   0%|          | 0/95 [00:00<?, ?it/s]/tmp/ipykernel_2006552/1555572793.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batched[key] = torch.cat([torch.tensor(item[key]) for item in input_list], dim=0)\n",
      "Embedding calculation: 100%|██████████| 95/95 [00:09<00:00,  9.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12148, 100, 64])\n"
     ]
    }
   ],
   "source": [
    "eazy_df = TimeEmbeddingRegressionDataset(df_raw, model, 100, apply_log=True, cnt_batchs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7290e+09)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eazy_df[:][1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "copy_value = deepcopy( eazy_df[:][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(eazy_df[:][1] - copy_value).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[227], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43meazy_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m eazy_df[:][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "eazy_df[:][1] -= eazy_df[:][1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512000"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eazy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=1)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.timedelta(seconds=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.MSELoss()(\n",
    "#     torch.tensor([3.]),\n",
    "#     torch.tensor([5.])\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "class SimpleRegressor(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyLinear(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def train_time_regressor(model, dataloader, num_epochs=100, lr=10, device='cuda', std=1, mean=0):\n",
    "    std = float(std)\n",
    "    mean = float(mean)\n",
    "    model = model.to(device)\n",
    "    # optimizer = torch.optim.LBFGS(model.parameters(), lr=lr, max_iter=1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        verbose=True,\n",
    "        min_lr=1e-7\n",
    "    )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for emb_time, target in tqdm(dataloader, desc=f\"Epoch {epoch + 1}\"):\n",
    "            # print(emb_time.shape,  emb_time.norm(2, 0).shape)\n",
    "            emb_time = emb_time / emb_time.norm(2, 0)\n",
    "            emb_time = emb_time.to(device)\n",
    "            target = (target.to(device).unsqueeze(-1).float() - mean) / std\n",
    "\n",
    "            # pred = model(emb_time)\n",
    "            # loss = criterion(pred, target)\n",
    "            def closure():\n",
    "                optimizer.zero_grad()\n",
    "                preds = model(emb_time)\n",
    "                loss = criterion(preds, target)\n",
    "                loss.backward()\n",
    "                return loss\n",
    "\n",
    "            loss = optimizer.step(closure)\n",
    "\n",
    "            # optimizer.zero_grad()\n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        scheduler.step(total_loss / len(dataloader))\n",
    "        # scheduler.get_lr()\n",
    "        avg_loss = (total_loss / len(dataloader)) ** 0.5 * std\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch + 1}\\nLr: {current_lr}\\nLoss: {avg_loss:.4f}\\ntimedelta {datetime.timedelta(seconds=avg_loss)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('13 days 16:31:02.194626560')"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(eazy_df[:][1].max() * 1e9) - pd.to_datetime(eazy_df[:][1].min() * 1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_model = SimpleRegressor(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader =  DataLoader(eazy_df, 2 ** 14, drop_last=True, num_workers=12, persistent_workers=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch 1:   0%|          | 0/74 [00:00<?, ?it/s]Exception ignored in: Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f5a131c3060>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f5a131c3060>  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f5a131c3060>\n",
      "    \n",
      "self._shutdown_workers()Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    <function _MultiProcessingDataLoaderIter.__del__ at 0x7f5a131c3060>        self._shutdown_workers()\n",
      "if w.is_alive():self._shutdown_workers()Exception ignored in: \n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "   File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "              if w.is_alive():self._shutdown_workers()if w.is_alive():\n",
      " Exception ignored in: \n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f5a131c3060>  Exception ignored in:    File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "\n",
      "   Traceback (most recent call last):\n",
      "       ^  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      " if w.is_alive(): ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f5a131c3060> \n",
      "    Exception ignored in:  ^\n",
      " <function _MultiProcessingDataLoaderIter.__del__ at 0x7f5a131c3060>self._shutdown_workers()  ^Exception ignored in: Traceback (most recent call last):\n",
      " \n",
      "\n",
      "  ^  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "^  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      " Traceback (most recent call last):\n",
      "^^^          File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      " ^^^self._shutdown_workers()if w.is_alive():<function _MultiProcessingDataLoaderIter.__del__ at 0x7f5a131c3060>    ^ ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f5a131c3060>^\n",
      "\n",
      "self._shutdown_workers()^\n",
      " ^\n",
      "^   File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "\n",
      "^Traceback (most recent call last):\n",
      " ^Traceback (most recent call last):\n",
      " ^  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "^  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    ^Exception ignored in: ^  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      " ^^if w.is_alive():    ^^ ^        ^\n",
      "self._shutdown_workers()^\n",
      " ^if w.is_alive():self._shutdown_workers()^ \n",
      "  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^ ^\n",
      " \n",
      "^  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "     ^^  ^  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f5a131c3060>^assert self._parent_pid == os.getpid(), 'can only test a child process'    ^^ ^     \n",
      "^\n",
      "if w.is_alive():\n",
      " \n",
      "^ if w.is_alive():^Traceback (most recent call last):\n",
      " \n",
      "  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "   File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^ ^\n",
      "   File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "          ^^    assert self._parent_pid == os.getpid(), 'can only test a child process'    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^ ^   \n",
      "self._shutdown_workers()^\n",
      "^^     ^\n",
      "^ ^^   \n",
      " ^   File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "^ ^   File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "  ^      ^ ^      ^  if w.is_alive():^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^  ^ ^\n",
      "^^\n",
      "  \n",
      " ^^^  ^   File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "  ^^  ^^^     ^^   ^^^assert self._parent_pid == os.getpid(), 'can only test a child process' ^^   ^^^\n",
      "^ ^   ^^ Exception ignored in: ^^ ^   ^\n",
      " ^^^^ ^^    File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^^^^ ^ ^^^    ^ ^\n",
      "^^ ^^^assert self._parent_pid == os.getpid(), 'can only test a child process' ^  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      " ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f5a131c3060>^^\n",
      "^\n",
      " ^     ^\n",
      "  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^^\n",
      " ^assert self._parent_pid == os.getpid(), 'can only test a child process' ^Traceback (most recent call last):\n",
      "    ^^  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^  \n",
      "^^  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'^    ^^   ^^\n",
      "^    assert self._parent_pid == os.getpid(), 'can only test a child process'^ ^  ^^ ^^self._shutdown_workers()\n",
      "^  ^ ^^^\n",
      "^ ^   ^^^^^  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "^    ^^^^^ ^      ^ ^^^^ ^if w.is_alive():  ^ ^^^ ^\n",
      "\n",
      "  ^ ^^ ^ ^  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^   ^^ ^^ ^ ^ ^    ^ ^^  ^^^ assert self._parent_pid == os.getpid(), 'can only test a child process' ^^ ^ ^^^^\n",
      " ^^^^ ^^^^  ^^^^ ^^^^^ ^^^ ^^^^^^^^ ^^^^^^^^^^^ ^^^^^^^^^^ ^^^^^^^^^^^^ ^^^^^\n",
      "^^^^ ^^^^AssertionError^^^^^ ^^^^: ^^^^^^ ^^^can only test a child process^^^^^^Exception ignored in: ^^ \n",
      "^^^^^^^^^^^ ^^\n",
      "^^^^^^^^AssertionError^^^^^^\n",
      "^: ^^^^^^\n",
      "can only test a child processAssertionError^^^^^^^  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f5a131c3060>\n",
      ": ^^^^^^^    \n",
      "can only test a child process^^^^^\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'Traceback (most recent call last):\n",
      "^^\n",
      "^^^^AssertionError\n",
      "  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "^^^^^^:  ^    ^^^^can only test a child process^ ^self._shutdown_workers()^\n",
      "^\n",
      "^^^ \n",
      "^^AssertionError^^ ^  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "^^:  ^^^^^can only test a child process     ^^^^\n",
      "^if w.is_alive(): ^^^^^ \n",
      "^^^^^  ^^^ ^^ ^^ ^\n",
      "^\n",
      " ^^^AssertionErrorAssertionError^ \n",
      "^: ^: ^ AssertionError^can only test a child process\n",
      "can only test a child process:  ^\n",
      "^\n",
      "AssertionErrorcan only test a child process ^^: \n",
      "^can only test a child process^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^  File \"/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "^\n",
      "^AssertionError ^ : ^ ^can only test a child process ^\n",
      " ^ ^^ ^ ^ ^ \n",
      " AssertionError^: ^can only test a child process^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([16384, 1, 1])) that is different to the input size (torch.Size([16384, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch 1: 100%|██████████| 74/74 [00:04<00:00, 17.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Lr: 1\n",
      "Loss: 273047.6362\n",
      "timedelta 3 days, 3:50:47.636164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 74/74 [00:02<00:00, 25.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "Lr: 1\n",
      "Loss: 265231.1123\n",
      "timedelta 3 days, 1:40:31.112309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 74/74 [00:02<00:00, 29.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      "Lr: 1\n",
      "Loss: 265633.3799\n",
      "timedelta 3 days, 1:47:13.379944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 74/74 [00:02<00:00, 27.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      "Lr: 1\n",
      "Loss: 265025.7394\n",
      "timedelta 3 days, 1:37:05.739438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 74/74 [00:02<00:00, 34.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n",
      "Lr: 1\n",
      "Loss: 265024.0446\n",
      "timedelta 3 days, 1:37:04.044611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 74/74 [00:01<00:00, 52.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n",
      "Lr: 1\n",
      "Loss: 264940.1975\n",
      "timedelta 3 days, 1:35:40.197486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 74/74 [00:01<00:00, 42.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n",
      "Lr: 1\n",
      "Loss: 264904.1834\n",
      "timedelta 3 days, 1:35:04.183427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 74/74 [00:02<00:00, 32.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n",
      "Lr: 1\n",
      "Loss: 264949.1283\n",
      "timedelta 3 days, 1:35:49.128296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 74/74 [00:02<00:00, 32.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n",
      "Lr: 1\n",
      "Loss: 265008.9600\n",
      "timedelta 3 days, 1:36:48.960040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 74/74 [00:02<00:00, 36.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n",
      "Lr: 1\n",
      "Loss: 265052.1003\n",
      "timedelta 3 days, 1:37:32.100259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 74/74 [00:01<00:00, 51.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11\n",
      "Lr: 1\n",
      "Loss: 265074.4028\n",
      "timedelta 3 days, 1:37:54.402834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 74/74 [00:02<00:00, 35.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12\n",
      "Lr: 1\n",
      "Loss: 265081.2735\n",
      "timedelta 3 days, 1:38:01.273540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 74/74 [00:02<00:00, 33.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13\n",
      "Lr: 0.5\n",
      "Loss: 265078.6709\n",
      "timedelta 3 days, 1:37:58.670887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 74/74 [00:02<00:00, 28.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14\n",
      "Lr: 0.5\n",
      "Loss: 264239.5431\n",
      "timedelta 3 days, 1:23:59.543148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 74/74 [00:02<00:00, 26.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15\n",
      "Lr: 0.5\n",
      "Loss: 264679.7003\n",
      "timedelta 3 days, 1:31:19.700272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 74/74 [00:02<00:00, 30.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16\n",
      "Lr: 0.5\n",
      "Loss: 264731.3862\n",
      "timedelta 3 days, 1:32:11.386237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 74/74 [00:01<00:00, 40.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17\n",
      "Lr: 0.5\n",
      "Loss: 264752.9763\n",
      "timedelta 3 days, 1:32:32.976259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 74/74 [00:02<00:00, 36.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18\n",
      "Lr: 0.5\n",
      "Loss: 264771.0972\n",
      "timedelta 3 days, 1:32:51.097206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 74/74 [00:02<00:00, 32.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19\n",
      "Lr: 0.5\n",
      "Loss: 264787.0784\n",
      "timedelta 3 days, 1:33:07.078403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 74/74 [00:02<00:00, 32.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20\n",
      "Lr: 0.25\n",
      "Loss: 264801.3861\n",
      "timedelta 3 days, 1:33:21.386070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 74/74 [00:02<00:00, 35.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21\n",
      "Lr: 0.25\n",
      "Loss: 264269.0225\n",
      "timedelta 3 days, 1:24:29.022478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 74/74 [00:01<00:00, 46.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22\n",
      "Lr: 0.25\n",
      "Loss: 264125.0216\n",
      "timedelta 3 days, 1:22:05.021590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 74/74 [00:02<00:00, 35.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23\n",
      "Lr: 0.25\n",
      "Loss: 264113.2801\n",
      "timedelta 3 days, 1:21:53.280080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 74/74 [00:02<00:00, 30.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24\n",
      "Lr: 0.25\n",
      "Loss: 264092.0019\n",
      "timedelta 3 days, 1:21:32.001927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 74/74 [00:02<00:00, 30.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25\n",
      "Lr: 0.25\n",
      "Loss: 264069.8556\n",
      "timedelta 3 days, 1:21:09.855590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 74/74 [00:02<00:00, 28.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26\n",
      "Lr: 0.25\n",
      "Loss: 264047.8332\n",
      "timedelta 3 days, 1:20:47.833238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 74/74 [00:01<00:00, 38.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27\n",
      "Lr: 0.25\n",
      "Loss: 264026.5147\n",
      "timedelta 3 days, 1:20:26.514652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 74/74 [00:01<00:00, 47.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28\n",
      "Lr: 0.25\n",
      "Loss: 264006.3061\n",
      "timedelta 3 days, 1:20:06.306100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 74/74 [00:01<00:00, 37.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29\n",
      "Lr: 0.25\n",
      "Loss: 263987.4823\n",
      "timedelta 3 days, 1:19:47.482284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 74/74 [00:02<00:00, 33.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30\n",
      "Lr: 0.25\n",
      "Loss: 263970.2183\n",
      "timedelta 3 days, 1:19:30.218275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 74/74 [00:02<00:00, 31.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31\n",
      "Lr: 0.25\n",
      "Loss: 263954.5906\n",
      "timedelta 3 days, 1:19:14.590630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 74/74 [00:01<00:00, 39.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32\n",
      "Lr: 0.25\n",
      "Loss: 263940.6162\n",
      "timedelta 3 days, 1:19:00.616221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 74/74 [00:01<00:00, 50.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33\n",
      "Lr: 0.25\n",
      "Loss: 263928.2601\n",
      "timedelta 3 days, 1:18:48.260139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 74/74 [00:01<00:00, 39.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34\n",
      "Lr: 0.25\n",
      "Loss: 263917.4585\n",
      "timedelta 3 days, 1:18:37.458497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 74/74 [00:02<00:00, 29.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35\n",
      "Lr: 0.25\n",
      "Loss: 263908.1110\n",
      "timedelta 3 days, 1:18:28.111032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 74/74 [00:02<00:00, 34.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36\n",
      "Lr: 0.25\n",
      "Loss: 263900.1076\n",
      "timedelta 3 days, 1:18:20.107619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 74/74 [00:02<00:00, 31.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37\n",
      "Lr: 0.25\n",
      "Loss: 263893.3349\n",
      "timedelta 3 days, 1:18:13.334930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 74/74 [00:01<00:00, 38.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38\n",
      "Lr: 0.25\n",
      "Loss: 263887.6616\n",
      "timedelta 3 days, 1:18:07.661645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 74/74 [00:01<00:00, 41.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39\n",
      "Lr: 0.25\n",
      "Loss: 263882.9765\n",
      "timedelta 3 days, 1:18:02.976492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 74/74 [00:01<00:00, 40.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40\n",
      "Lr: 0.25\n",
      "Loss: 263879.1590\n",
      "timedelta 3 days, 1:17:59.158989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 74/74 [00:02<00:00, 34.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41\n",
      "Lr: 0.25\n",
      "Loss: 263876.0975\n",
      "timedelta 3 days, 1:17:56.097510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 74/74 [00:02<00:00, 31.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42\n",
      "Lr: 0.25\n",
      "Loss: 263873.6918\n",
      "timedelta 3 days, 1:17:53.691826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 74/74 [00:01<00:00, 40.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43\n",
      "Lr: 0.25\n",
      "Loss: 263871.8467\n",
      "timedelta 3 days, 1:17:51.846664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 74/74 [00:01<00:00, 52.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44\n",
      "Lr: 0.25\n",
      "Loss: 263870.4772\n",
      "timedelta 3 days, 1:17:50.477205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 74/74 [00:02<00:00, 31.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45\n",
      "Lr: 0.25\n",
      "Loss: 263869.5119\n",
      "timedelta 3 days, 1:17:49.511934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 74/74 [00:02<00:00, 31.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46\n",
      "Lr: 0.25\n",
      "Loss: 263868.8797\n",
      "timedelta 3 days, 1:17:48.879652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 74/74 [00:02<00:00, 31.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47\n",
      "Lr: 0.25\n",
      "Loss: 263868.5200\n",
      "timedelta 3 days, 1:17:48.520037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 74/74 [00:02<00:00, 34.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48\n",
      "Lr: 0.25\n",
      "Loss: 263868.3885\n",
      "timedelta 3 days, 1:17:48.388509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 74/74 [00:02<00:00, 34.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49\n",
      "Lr: 0.25\n",
      "Loss: 263868.4382\n",
      "timedelta 3 days, 1:17:48.438163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 74/74 [00:01<00:00, 50.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "Lr: 0.25\n",
      "Loss: 263868.6308\n",
      "timedelta 3 days, 1:17:48.630753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 74/74 [00:01<00:00, 41.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51\n",
      "Lr: 0.125\n",
      "Loss: 263868.9396\n",
      "timedelta 3 days, 1:17:48.939552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52:  11%|█         | 8/74 [00:00<00:05, 12.39it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[307], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_time_regressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meazy_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meazy_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[302], line 52\u001b[0m, in \u001b[0;36mtrain_time_regressor\u001b[0;34m(model, dataloader, num_epochs, lr, device, std, mean)\u001b[0m\n\u001b[1;32m     49\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[0;32m---> 52\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# optimizer.zero_grad()\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# optimizer.step()\u001b[39;00m\n\u001b[1;32m     58\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/optim/adam.py:223\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 223\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    226\u001b[0m     params_with_grad: List[Tensor] \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[302], line 47\u001b[0m, in \u001b[0;36mtrain_time_regressor.<locals>.closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclosure\u001b[39m():\n\u001b[1;32m     46\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 47\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(preds, target)\n\u001b[1;32m     49\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[302], line 16\u001b[0m, in \u001b[0;36mSimpleRegressor.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_time_regressor(time_model, dataloader,\n",
    "                     lr=1, device=device, std=eazy_df[:][1].std(), mean=eazy_df[:][1].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7289e+09])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eazy_df[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "def plot_time_predictions(model, dataloader, device='cuda', mean=0.0, std=1.0):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for emb_time, target in tqdm(dataloader, desc=\"Predicting\"):\n",
    "            emb_time = emb_time / emb_time.norm(2, 0)\n",
    "            emb_time = emb_time.to(device)\n",
    "            target = target.unsqueeze(-1).float().to(device)\n",
    "\n",
    "            preds = model(emb_time)\n",
    "            preds_real = preds * std + mean\n",
    "            targets_real = target\n",
    "\n",
    "            all_preds.append(preds_real.cpu())\n",
    "            all_targets.append(targets_real.cpu())\n",
    "\n",
    "    preds_tensor = torch.cat(all_preds).squeeze().numpy()[::10]\n",
    "    targets_tensor = torch.cat(all_targets).squeeze().numpy()[::10]\n",
    "\n",
    "    # Перевод в datetime (unix time → datetime)\n",
    "    # preds_datetime = [datetime.fromtimestamp(ts) for ts in preds_tensor]\n",
    "    # targets_datetime = [datetime.fromtimestamp(ts) for ts in targets_tensor]\n",
    "\n",
    "    preds_datetime = [datetime.fromtimestamp(float(ts)) for ts in preds_tensor]\n",
    "    targets_datetime = [datetime.fromtimestamp(float(ts)) for ts in targets_tensor]\n",
    "\n",
    "\n",
    "    # Построение\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(targets_datetime, preds_datetime, alpha=0.3, s=8)\n",
    "    # plt.plot(\n",
    "    #     [min(targets_datetime), max(targets_datetime)],\n",
    "    #     [min(targets_datetime), max(targets_datetime)],\n",
    "    #     color='red', linestyle='--', label='y = x (ideal)'\n",
    "    # )\n",
    "    plt.xlabel(\"True Time\")\n",
    "    plt.ylabel(\"Predicted Time\")\n",
    "    plt.title(\"Predicted vs True Time\")\n",
    "\n",
    "    plt.ylim(min(preds_datetime), max(preds_datetime))\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 74/74 [00:15<00:00,  4.93it/s]\n",
      "/tmp/ipykernel_2006552/2181089304.py:47: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
      "  plt.ylim(min(preds_datetime), max(preds_datetime))\n",
      "/tmp/ipykernel_2006552/2181089304.py:49: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataloader_final =  DataLoader(eazy_df, 2 ** 14, drop_last=True, num_workers=0, shuffle=False)\n",
    "\n",
    "\n",
    "plot_time_predictions(time_model, dataloader_final, device, eazy_df[:][1].mean(), eazy_df[:][1].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# plot_predictions(time_model, DataLoader(eazy_df, 2 ** 14, drop_last=True, num_workers=12), device, coef=eazy_df[:][1].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(eazy_df[0][0], dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (eazy_df[0][0] ** 2).sum(0) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  torch.norm(eazy_df[0][0], 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (eazy_df[0][0] / torch.norm(eazy_df[0][0], 2, 0)).diff(1).norm(2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/1214800 [00:00<?, ?it/s]/home/motatasher/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch 1:   0%|          | 1643/1214800 [00:03<41:00, 493.13it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[244], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_time_regressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSimpleRegressor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meazy_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[233], line 41\u001b[0m, in \u001b[0;36mtrain_time_regressor\u001b[0;34m(model, dataloader, num_epochs, lr, device)\u001b[0m\n\u001b[1;32m     38\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[0;32m---> 41\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# optimizer.zero_grad()\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# optimizer.step()\u001b[39;00m\n\u001b[1;32m     47\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/optim/lbfgs.py:451\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    448\u001b[0m     opt_cond \u001b[38;5;241m=\u001b[39m flat_grad\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tolerance_grad\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;66;03m# no line search, simply move with fixed-step\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_iter \u001b[38;5;241m!=\u001b[39m max_iter:\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;66;03m# re-evaluate function only if not in last iteration\u001b[39;00m\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;66;03m# the reason we do this: in a stochastic setting,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;66;03m# no use to re-evaluate that function here\u001b[39;00m\n\u001b[1;32m    456\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n",
      "File \u001b[0;32m~/miniconda3/envs/DiplomaIsupov/lib/python3.12/site-packages/torch/optim/lbfgs.py:283\u001b[0m, in \u001b[0;36mLBFGS._add_grad\u001b[0;34m(self, step_size, update)\u001b[0m\n\u001b[1;32m    281\u001b[0m     numel \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# view as to avoid deprecated pointwise semantics\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     p\u001b[38;5;241m.\u001b[39madd_(\u001b[43mupdate\u001b[49m\u001b[43m[\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m, alpha\u001b[38;5;241m=\u001b[39mstep_size)\n\u001b[1;32m    284\u001b[0m     offset \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m numel\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m offset \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numel()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_time_regressor(SimpleRegressor(32), eazy_df, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43meazy_df\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[73], line 28\u001b[0m, in \u001b[0;36mTimeEmbeddingRegressionDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     26\u001b[0m from_ind \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m to_ind \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 28\u001b[0m numeric_features \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m volume_converter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: x\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_log\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "\u001b[0;31mValueError\u001b[0m: could not determine the shape of object type 'Series'"
     ]
    }
   ],
   "source": [
    "for a, b in eazy_df:\n",
    "    print(b.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DiplomaIsupov",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
