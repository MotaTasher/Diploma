defaults:
    - default
    - _self_


dataset_fabric: "GetEthereumDataset"

name: "model training on eth dataset v1, tensor predict"
df_config:
    start_block: 20_900_000
    end_block: 21_500_000
    # end_block: 20_930_000
    # address_limit: 10_000
    use_async: False

model: "BertForTransactionRegressionV1"

show_batch_size: 100

model_params:
    # (emb_size + time_features + 1) * 2 % num_attention_heads == 0
    emb_size: 2
    num_attention_heads: 12
    # use_compositor: True
    use_compositor: False
    time_features: 69
    bert_config:
        vocab_size: 30522
        hidden_size: 768
        num_hidden_layers: 12
        num_attention_heads: 12
        intermediate_size: 3072
        hidden_act: "gelu"
        hidden_dropout_prob: 0.1
        attention_probs_dropout_prob: 0.1
        max_position_embeddings: 512
        type_vocab_size: 2
        initializer_range: 0.02
        layer_norm_eps: 1e-12
        pad_token_id: 0
        position_embedding_type: "absolute"
        use_cache: True

learning_rate: 1e-5

gamma: 0.6
step_size: 5
warmup_epochs: 1
threshold: 0.05

num_epochs: 2_000

model_predictor: "time_cross_predictior" # time_cross_predictior 
result_loss: "result_loss_slower_change" # result_loss_slower_change, result_loss_empty

use_log: True

train_batch_size: 512
test_batch_size: 64

scheduler: reduce_on_plateau